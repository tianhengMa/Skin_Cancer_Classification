{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section we use Bag of Visual Words model to classify images of skin cancers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "#from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the HMNIST dataset. Each datapoint is a 28 by 28 grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hmnist_dataset = pd.read_csv(\"hmnist_28_28_L.csv\").to_numpy()\n",
    "hmnist_dataset = pd.read_csv(\"hmnist_28_28_L.csv\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewcolumn(columnvector);\n",
    "# VIEWCOLUMN Displays a 28 x 28 grayscale image stored in a column vector.\n",
    "# Tim Marks 2002\n",
    "\n",
    "def viewcolumn(columnvector):\n",
    "    plt.imshow(columnvector.reshape([28,28], order='F'), cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visual_words(image, kmeans_model, patch_size=patch_size):\n",
    "    patches = extract_patches_2d(image.reshape([28,28]), (patch_size, patch_size))\n",
    "    visual_words = kmeans_model.predict(patches.reshape([len(patches),patch_size*patch_size]))\n",
    "    hist, _ = np.histogram(visual_words, bins=range(kmeans_model.n_clusters))\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_patches(images, patch_size):\n",
    "    patches = []\n",
    "    for i in range(len(images)):\n",
    "        image_patches = extract_patches_2d(images[i].reshape([28,28]), (patch_size, patch_size))\n",
    "        for patch in image_patches:\n",
    "            patches.append(patch)\n",
    "    return np.array(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAATo0lEQVR4nO3dX4yc1XkG8OfxYsza+8dru/4DMXUSECpCKqlWViWqiipqRLiBXKQKSBGRUJ2LICVSLoroRbhEVZMoF1Ukp6A4VUoUKUFwgdogFAnlJmJBDpiaP65lzMLaG7w2Xttr7N19e7GDtIH93mcyZ3Zm0vP8JGvXc/b7vjPfzLszO893zmFEwMz+/9vQ7w6YWW+42M0q4WI3q4SL3awSLnazSlzTy4MNDw/H2NhYY/vGjRvT7bP2DRvW9/dWllqQTLcdGhpK21Xf1f5LqDRmeXm5aP8lfS/tW7a92vfS0lLafvXq1bT9ypUrHW+v9p31bXFxEUtLS2ue9KJiJ3kXgB8AGALw7xHxWPbzY2NjuP/++xvbd+/enR4va7/uuuvSbZVrrslPRfYAqGLNfsEBwObNm9N2dd+yJ64qCPWkvnTpUsfHBvJf0OqX4Icffpi2q75l900V1NzcXNp++vTptP2dd95J22dmZjpqA4D5+fnGtunp6ca2jl8OSQ4B+DcAXwRwK4D7SN7a6f7MbH2VvPfdD+BYRByPiCsAfgbgnu50y8y6raTYbwCw+r3KdOu2P0DyAMkpklMLCwsFhzOzEiXFvtaHAJ/4Ay4iDkbEZERMDg8PFxzOzEqUFPs0gL2r/v8pAO+VdcfM1ktJsb8I4GaSnyZ5LYCvAHimO90ys27rOHqLiEWSDwH4b6xEb09ExGvZNsPDw7jtttsa27du3Zoec9OmTY1tKjpTuaeKkHbu3NnYpqI1ZXFxMW0vyZMVdW3DxMREx/sG8r6rz3CuvfbaomNn+1fPl127dqXtW7ZsSdvVecueTzt27Ei3zWK92dnZxrainD0ingXwbMk+zKw3fLmsWSVc7GaVcLGbVcLFblYJF7tZJVzsZpXo6Xj2oaEhjIyMNLZnOTqQ564qi1bDRNXw2hIqy1Z9K8nZS8ddq2Go6r5l+1ePtxp+q2R9v3jxYrqtGoc/Pj6etmfPcyC/NmPbtm3pttu3b29sO3r0aGObX9nNKuFiN6uEi92sEi52s0q42M0q4WI3q0TPo7dsGKuKWrKoRkVEagZXNUw0i8dUdFY6i2rJdMxq32qopxp+W/KYqSGsKhZUfbt8+XJjmxqiqs6bouLSLD5TQ6az9uy56Fd2s0q42M0q4WI3q4SL3awSLnazSrjYzSrhYjerRE9zdkWthppl4aXTOatprLOsW+XBql1RWXiW46uhlorKskvuW8kKsKXtpdcfqL6XPCfUvrNrRrIa8iu7WSVc7GaVcLGbVcLFblYJF7tZJVzsZpVwsZtVoqc5O8k0v1TZZpZ1nzt3Lt123759absa3zw3N5e2Z9R49tL2LJdVY8ZLxsqrY6v9q/tVOpV0NpZe3W91bHVNiNp/dt/V9N/ZY5rWV7pXgeQJAPMAlgAsRsRkyf7MbP1045X97yLi/S7sx8zWkf9mN6tEabEHgF+RfInkgbV+gOQBklMkp9Tf1Wa2fkrfxt8REe+R3AngOZKvR8QLq38gIg4COAgAt9xyS/5pjpmtm6JX9oh4r/V1FsBTAPZ3o1Nm1n0dFzvJLSRHP/oewBcAHOlWx8ysu0rexu8C8FQrT7wGwH9GxH+VdEZlwtmc2Grctso9FxYW0vaSzFbNIV6as2fnRd0v1XeVo6u8OXtMVZ5ceuxLly51vO3o6GjaPj8/n7arsfbZfVNzCGTPxex+dVzsEXEcwF92ur2Z9ZajN7NKuNjNKuFiN6uEi92sEi52s0r0fCppFSNlxsfHG9tKl01WMVA25FFFRKXTFqtpsrOopjT2UzGQkh2/ZEhzO7L7pqIxNRW0GhJd8nxS+87OaXbO/MpuVgkXu1klXOxmlXCxm1XCxW5WCRe7WSVc7GaV6GnOvmHDhnS52awNyIexqixbTQ2s8uSsXW2rhu6qvFllwtn+1fUHly9fTtvVY1KS06ssWlHnPeubytHVtRPZMFOgbPlxdW2E6ltjnzraysz+5LjYzSrhYjerhIvdrBIudrNKuNjNKuFiN6vEQC3ZvG3bNrl9k5Jx8oCeGjjLdFWWrZRm2VnuqpaaVlm1mqJbyR4zlXUrJdNYq2sbFJWFK+q6kEzWd49nNzMXu1ktXOxmlXCxm1XCxW5WCRe7WSVc7GaV6Pl49mxObJVXl8yPrsazlyz5rMYXq3aVo6v7dvz48ca2d999N91WufHGG9N2lReXLLOtxvGrxzQ7b+qcqhx+PdcKUNcfqPPSRL6yk3yC5CzJI6tu20byOZJvtb5OdHR0M+uZdt7G/xjAXR+77WEAz0fEzQCeb/3fzAaYLPaIeAHAx6+5vAfAodb3hwDc2+V+mVmXdfoB3a6ImAGA1tedTT9I8gDJKZJTZ8+e7fBwZlZq3T+Nj4iDETEZEZMTE/7T3qxfOi320yT3AEDr62z3umRm66HTYn8GwAOt7x8A8HR3umNm60Xm7CSfBHAngB0kpwF8B8BjAH5O8kEAJwF8uZ2DDQ0NYXR0tLFd5abZHOdq25J5vAFgeHi44207nef7IxcvXkzbFxYWOt739u3b0/bZ2fxN2/T0dNqe5dk33XRTuu2+ffvS9uy5BACXLl1qbCtdG17l6GqegGx7dd1Ftm32XJPFHhH3NTR9Xm1rZoPDl8uaVcLFblYJF7tZJVzsZpVwsZtVoqdDXIE8VlBxRkmEpZZNVrIIScV6annfY8eOpe0zMzNpezYMVR07i6cA4Pz582m7ijyzyPLkyZMdbwsA4+PjaXs2nFrFmSr+UudNTU2enTc1hDVr91TSZuZiN6uFi92sEi52s0q42M0q4WI3q4SL3awSPc/Zs3zx6tWr6bZZzq5yUTWkUeXw2TUAat+ly/teuHAhbc+WZVbnRU1bnA0rBoA9e/ak7dkw1A8++CDd9syZM2n7qVOn0vbrr7++sU1df6Dud5bhA/q8Z0NgS64nya758Cu7WSVc7GaVcLGbVcLFblYJF7tZJVzsZpVwsZtVoqc5O8k0k1Y5e6dT6Lazb5WLZssLl2b4O3c2rp4FQGfh2dhslfGrY2/dujVtV9cAZEt+qSW61TwBKgvPxnarx0RNBa2o7bPnm5ojoNO++ZXdrBIudrNKuNjNKuFiN6uEi92sEi52s0q42M0q0dOcPSLSDFHlqlk2WboEr5Jl2erYaklllfGr87J58+bGNpXZqjHjqm/q+oZs3Ld6TCYmJtL2vXv3pu1Z31RWnV1XAehrH9T1Ddk1I+q8ZI9pdp/lKzvJJ0jOkjyy6rZHSb5L8nDr391qP2bWX+28jf8xgLvWuP37EXF769+z3e2WmXWbLPaIeAFA87xHZvYnoeQDuodIvtJ6m9/4xxXJAySnSE6pvw/NbP10Wuw/BPBZALcDmAHw3aYfjIiDETEZEZPbt2/v8HBmVqqjYo+I0xGxFBHLAH4EYH93u2Vm3dZRsZNcPX/wlwAcafpZMxsMMmcn+SSAOwHsIDkN4DsA7iR5O4AAcALA19s5GMk0t1V5cska6WqdcbUmdpZ9qpxdtatj7969O23PMmO1xrlap1ytQ67Gw6vHJaPGnKvzlmXhKgdXc9qr6xdUe/Z8UtcAZJ99ZdvKYo+I+9a4+XG1nZkNFl8ua1YJF7tZJVzsZpVwsZtVwsVuVomeDnFdXFxMpxbOlvcF8rhCDQtU0xaraYmzGEgt/6siIkUN9cziFhVfjY2Npe1qCKuKiUqW2VbxmGrPjq2mFlfRmRriqs5LdvzZ2dl0206XAPcru1klXOxmlXCxm1XCxW5WCRe7WSVc7GaVcLGbVaKnOfvS0lI6dFANBc2Ga6qcXGW6KofPtleZq6JyeJV1Z+dN3W+VJ6tjqyWbs+sfsimw2zm2mqI7O7bK2UtzdNW3ubnmaR3V8yFrz4YU+5XdrBIudrNKuNjNKuFiN6uEi92sEi52s0q42M0q0dOcfXl5Oc0f1bTGWS5bmierjD9TOuZbTfesxqRn2arqm8qbVbvqW0adF5V1Z8seA/ljqo6trtuYn5/v+NhAfl1H6TLZTfzKblYJF7tZJVzsZpVwsZtVwsVuVgkXu1klXOxmlehpzk4yzYRVzp6N41Vjo9W88ipPzqhMVWXRKvNVyyZn9610znp1fYLKutV5z6g8WV2fkM2vrs6pah8ZGUnb1XMiu95EXV/Q6foJ8pWd5F6SvyZ5lORrJL/Zun0byedIvtX6mq9kYGZ91c7b+EUA346IvwDw1wC+QfJWAA8DeD4ibgbwfOv/ZjagZLFHxExEvNz6fh7AUQA3ALgHwKHWjx0CcO96ddLMyv1RH9CR3AfgcwB+C2BXRMwAK78QAOxs2OYAySmSU+fOnSvrrZl1rO1iJzkC4BcAvhUR59vdLiIORsRkRExu3bq1kz6aWRe0VewkN2Kl0H8aEb9s3Xya5J5W+x4A+dKTZtZXMnrjymf5jwM4GhHfW9X0DIAHADzW+vq02ldEdLzcLJDHYyriUVGIir+yIYklMQtQNlQTyIdEqqGaJZEjUDbNdWkcqu5bFuWqeEtFlqrv6jHPnm8lQ3+z+monZ78DwFcBvErycOu2R7BS5D8n+SCAkwC+3Ma+zKxPZLFHxG8ANP0a+3x3u2Nm68WXy5pVwsVuVgkXu1klXOxmlXCxm1Wip0NcgTxDLBkOqbJqNT2vylWzbFMNA1X3S117oPLmbP8qs1VUlq3uW0nfSpdsLrkuo3Ror8rxs76r85K1Z/32K7tZJVzsZpVwsZtVwsVuVgkXu1klXOxmlXCxm1Wipzl7RKTZp8pNszx6dHQ03XbTpk1pu9o+O7bK8FWmqzJZNZ49y1ZLlqIGdJ6szmvJlMmKuv4gzZyTKc3b2XfJNSFA/ny6cOFCum2Ws2f79Su7WSVc7GaVcLGbVcLFblYJF7tZJVzsZpVwsZtVoufj2TNqaeMsN1VLS6k8WOWqKksvObYaz67as3HfKidX47bVsc+ePZu2Zzm/erxLli5WSucgUM8XleNnzyd1bcT777/f2JZl8H5lN6uEi92sEi52s0q42M0q4WI3q4SL3awSLnazSrSzPvteAD8BsBvAMoCDEfEDko8C+EcAv2/96CMR8Wy2r+Xl5XQe8omJibQv2RrppeuMZ2t5A3kuqvLiubm5tF2NpVeZb5atlqyfDug8umRMupofXV0jsHnz5rQ9u0ZA7VtdX1AytzuQXxdy8uTJdNsTJ040tmX11c5FNYsAvh0RL5McBfASyedabd+PiH9tYx9m1mftrM8+A2Cm9f08yaMAbljvjplZd/1Rf7OT3AfgcwB+27rpIZKvkHyC5JrvwUkeIDlFcur8+fNFnTWzzrVd7CRHAPwCwLci4jyAHwL4LIDbsfLK/921touIgxExGRGTY2NjXeiymXWirWInuRErhf7TiPglAETE6YhYiohlAD8CsH/9umlmpWSxc+Wj4McBHI2I7626fc+qH/sSgCPd756ZdUs7n8bfAeCrAF4lebh12yMA7iN5O4AAcALA19WOlpeX02lyVcQ0MjLS2Kbir9Jlk7N2FW+p4Y6lsphHRZLZOQX00F7VnkV7pdM1q6nHs8dFRYYqOlPbnzp1Km0/fvx4Y9ubb76ZbvvGG280ts3Pzze2tfNp/G8ArHXW00zdzAaLr6Azq4SL3awSLnazSrjYzSrhYjerhIvdrBI9nUp6YWEBr7/+emO7Guq5e/fuxjaVF4+Pj+edE7LMV+XFJVNkAzrL3rhxY2Nb6dLCant1DYG6byXbqiw8e1zUkOYzZ86k7bOzs2n722+/nbZndaBydnXsJn5lN6uEi92sEi52s0q42M0q4WI3q4SL3awSLnazSlCNxe7qwcjfA1gdQO4A0Lz+bH8Nat8GtV+A+9apbvbtzyPiz9Zq6Gmxf+Lg5FRETPatA4lB7dug9gtw3zrVq775bbxZJVzsZpXod7Ef7PPxM4Pat0HtF+C+daonfevr3+xm1jv9fmU3sx5xsZtVoi/FTvIukm+QPEby4X70oQnJEyRfJXmY5FSf+/IEyVmSR1bdto3kcyTfan3N17nubd8eJflu69wdJnl3n/q2l+SvSR4l+RrJb7Zu7+u5S/rVk/PW87/ZSQ4BeBPA3wOYBvAigPsi4n962pEGJE8AmIyIvl+AQfJvAVwA8JOIuK11278AmIuIx1q/KCci4p8GpG+PArjQ72W8W6sV7Vm9zDiAewF8DX08d0m//gE9OG/9eGXfD+BYRByPiCsAfgbgnj70Y+BFxAsA5j528z0ADrW+P4SVJ0vPNfRtIETETES83Pp+HsBHy4z39dwl/eqJfhT7DQDeWfX/aQzWeu8B4FckXyJ5oN+dWcOuiJgBVp48AHb2uT8fJ5fx7qWPLTM+MOeuk+XPS/Wj2Nea1GyQ8r87IuKvAHwRwDdab1etPW0t490raywzPhA6Xf68VD+KfRrA3lX//xSA9/rQjzVFxHutr7MAnsLgLUV9+qMVdFtfO5t9cB0M0jLeay0zjgE4d/1c/rwfxf4igJtJfprktQC+AuCZPvTjE0huaX1wApJbAHwBg7cU9TMAHmh9/wCAp/vYlz8wKMt4Ny0zjj6fu74vfx4RPf8H4G6sfCL/vwD+uR99aOjXZwD8rvXvtX73DcCTWHlbdxUr74geBLAdwPMA3mp93TZAffsPAK8CeAUrhbWnT337G6z8afgKgMOtf3f3+9wl/erJefPlsmaV8BV0ZpVwsZtVwsVuVgkXu1klXOxmlXCxm1XCxW5Wif8DelMDe4GVjY4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "viewcolumn(hmnist_dataset[8][0:784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data set into training (75%), validation (15%), and test (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 784\n",
    "hmnist_X = hmnist_dataset.T[0:dimension].T\n",
    "hmnist_y  = hmnist_dataset.T[dimension].T\n",
    "\n",
    "# First split the whole dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(hmnist_X, hmnist_y, test_size=0.25)\n",
    "# Then split the test dataset into validation and test\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the hyperparameters for this model. They can be tuned to get better prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 8\n",
    "n_clusters = 10\n",
    "knn_neighbors = 20\n",
    "#c= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is 0.683755\n"
     ]
    }
   ],
   "source": [
    "#Extract 2D patches (features) from the image\n",
    "patches = images_to_patches(X_train,patch_size)\n",
    "#Run KMeans on the extracted patches\n",
    "kmeans_model = MiniBatchKMeans(n_clusters=n_clusters, random_state=0).fit(patches.reshape([len(patches),patch_size*patch_size]))\n",
    "#Get visual words for all the images (use kmeans features to label each training image)\n",
    "X_train_hist = [get_visual_words(image, kmeans_model, patch_size) for image in X_train]\n",
    "#Train the trained histograms with training label using SVM\n",
    "#clf = SVC(C=c,gamma='auto')\n",
    "#clf.fit(X_train_hist,y_train)\n",
    "knn_model = KNN(n_jobs=-1,n_neighbors=knn_neighbors,weights='uniform')\n",
    "knn_model.fit(X_train_hist,y_train)\n",
    "\n",
    "#Test validation accuracy\n",
    "X_valid_hist = [get_visual_words(image, kmeans_model, patch_size) for image in X_valid]\n",
    "#valid_pred = clf.predict(X_valid_hist)\n",
    "valid_pred = knn_model.predict(X_valid_hist)\n",
    "valid_result = []\n",
    "for i in range(len(y_valid)):\n",
    "    if (y_valid[i] == valid_pred[i]):\n",
    "        valid_result.append(1)\n",
    "    else:\n",
    "        valid_result.append(0)\n",
    "valid_accuracy = sum(valid_result) / len(y_valid)\n",
    "\n",
    "print(\"Validation accuracy is %f\" %valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.669661\n"
     ]
    }
   ],
   "source": [
    "#Test test accuracy\n",
    "X_test_hist = [get_visual_words(image, kmeans_model, patch_size) for image in X_test]\n",
    "#test_pred = clf.predict(X_test_hist)\n",
    "test_pred = knn_model.predict(X_test_hist)\n",
    "test_result = []\n",
    "for i in range(len(y_test)):\n",
    "    if (y_test[i] == test_pred[i]):\n",
    "        test_result.append(1)\n",
    "    else:\n",
    "        test_result.append(0)\n",
    "test_accuracy = sum(test_result) / len(y_test)\n",
    "\n",
    "print(\"Test accuracy is %f\" %test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
